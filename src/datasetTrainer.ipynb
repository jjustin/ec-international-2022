{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "from dataset import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model loader\n",
    "This part of code loads the model and contains optional state file loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SpaghettiModel().to(device)\n",
    "model.load_state_dict(torch.load('models/spaghettiAlPestoETonno.pth'))\n",
    "model.eval()\n",
    "\n",
    "dataset = SensorCameraDataset(pesto1 + tonno )\n",
    "train_size = round(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "sample = train_dataset[0][0]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# device = \"cuda\"\n",
    "# from models import *\n",
    "\n",
    "# model = SpaghettiModel().to(device)\n",
    "\n",
    "# summary(model, (3,64,64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainging\n",
    "In this part the model is trained using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "history = torch.zeros((1,AnelliModel.HISTORY_LEN)).to(device)\n",
    "for epoch in tqdm_notebook(range(15)):\n",
    "    for sample, label in train_loader:\n",
    "        sample = sample.to(device=device, dtype=torch.float)\n",
    "        label = label.to(device=device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = model(sample)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "Here, confusion matrix is generated from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "y_pred = [3]\n",
    "y_true = [3]\n",
    "\n",
    "for sample, labels in test_loader:\n",
    "    sample = sample.to(device=device, dtype=torch.float)\n",
    "    labels = labels.to(device=device, dtype=torch.float)\n",
    "\n",
    "    output = model(sample)\n",
    "\n",
    "    output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "    labels = (torch.max(labels,1)[1]).data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "classes = (0,1,2,3)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plot.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/spaghettiAlPestoETonno.pth\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01ca3796a35d0eee18d928ce6bcb6ceb711861d64ee73f0b7f7437f32c63f40a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
